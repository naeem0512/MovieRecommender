{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYgq_BlkGK86"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import requests\n",
        "\n",
        "# Download the MovieLens dataset\n",
        "url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "response = requests.get(url)\n",
        "with open('movielens.zip', 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Extract the zip file contents\n",
        "with zipfile.ZipFile('movielens.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the ratings.csv file\n",
        "ratings = pd.read_csv('ml-latest-small/ratings.csv',\n",
        "                      header=0,\n",
        "                      sep=',',\n",
        "                      quotechar='\"',\n",
        "                      usecols=['userId', 'movieId', 'rating'])\n",
        "\n",
        "ratings.dropna(inplace=True)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create user-item matrix\n",
        "user_item_matrix = train_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "j5HfRt6cGSsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Singular Value Decomposition (SVD)\n",
        "svd = TruncatedSVD(n_components=50, random_state=42)\n",
        "matrix_svd = svd.fit_transform(user_item_matrix)\n"
      ],
      "metadata": {
        "id": "6oekuzxH0-DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set preprocessing for SVD\n",
        "test_user_item_matrix = test_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "train_movie_ids = train_data['movieId'].unique()\n",
        "test_movie_ids = test_data['movieId'].unique()\n",
        "\n",
        "# Identify movies in test set but not in training set\n",
        "missing_movie_ids = set(test_movie_ids) - set(train_movie_ids)\n",
        "\n",
        "# Add missing movie columns to test_user_item_matrix filled with zeros\n",
        "for movie_id in missing_movie_ids:\n",
        "    test_user_item_matrix[movie_id] = 0\n",
        "\n",
        "# Get intersection of movie ids to ensure common columns\n",
        "common_movie_ids = list(set(train_movie_ids) & set(test_user_item_matrix.columns))\n",
        "\n",
        "# Reorder columns of test_user_item_matrix to match training matrix\n",
        "test_user_item_matrix = test_user_item_matrix.reindex(columns=train_movie_ids).fillna(0)\n",
        "\n",
        "# Apply the transformation\n",
        "test_svd = svd.transform(test_user_item_matrix)\n",
        "predictions = np.dot(test_svd, svd.components_)\n",
        "\n",
        "mse = mean_squared_error(test_user_item_matrix.values, predictions)\n",
        "print(\"SVD Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "0TCnIRuw1BHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD-based recommendations\n",
        "def recommend_movies(user_id, num_recommendations):\n",
        "    user_row = user_item_matrix.loc[user_id].values.reshape(1, -1)\n",
        "    user_svd = svd.transform(user_row)\n",
        "    scores = np.dot(user_svd, svd.components_)\n",
        "    movie_ids = np.argsort(scores[0])[::-1][:num_recommendations]\n",
        "    return movie_ids\n"
      ],
      "metadata": {
        "id": "CQz34yEC1FQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate cosine similarity for user-based collaborative filtering\n",
        "user_similarity = cosine_similarity(user_item_matrix)\n",
        "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
        "\n",
        "# Function to recommend movies using user-based collaborative filtering\n",
        "def user_based_recommendations(user_id, num_recommendations, num_neighbors=10):\n",
        "    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:num_neighbors+1]\n",
        "    similar_users_ratings = user_item_matrix.loc[similar_users].mean(axis=0)\n",
        "    user_rated_movies = user_item_matrix.loc[user_id].replace(0, np.nan).dropna().index\n",
        "    recommendations = similar_users_ratings.drop(user_rated_movies).sort_values(ascending=False).index[:num_recommendations]\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "s1D-ojGN1H1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate cosine similarity for item-based collaborative filtering\n",
        "item_similarity = cosine_similarity(user_item_matrix.T)\n",
        "item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n",
        "\n",
        "# Function to recommend movies using item-based collaborative filtering\n",
        "def item_based_recommendations(user_id, num_recommendations, num_neighbors=10):\n",
        "    user_ratings = user_item_matrix.loc[user_id]\n",
        "    similar_items = pd.Series(dtype=float)\n",
        "    for movie, rating in user_ratings[user_ratings > 0].items():\n",
        "        similar_items = similar_items.add(item_similarity_df[movie].drop(movie) * rating, fill_value=0)\n",
        "    similar_items = similar_items.groupby(similar_items.index).sum()\n",
        "    user_rated_movies = user_ratings.replace(0, np.nan).dropna().index\n",
        "    recommendations = similar_items.drop(user_rated_movies).sort_values(ascending=False).index[:num_recommendations]\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "GYeIHSUt1OqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_svd_model(svd, num_recommendations=5):\n",
        "    user_item_matrix_svd = svd.transform(user_item_matrix)\n",
        "    mse_list = []\n",
        "    for user_id in test_data['userId'].unique():\n",
        "        actual_ratings = test_data[test_data['userId'] == user_id]\n",
        "        user_row = user_item_matrix.loc[user_id].values.reshape(1, -1)\n",
        "        user_svd = svd.transform(user_row)\n",
        "        scores = np.dot(user_svd, svd.components_)\n",
        "        movie_ids = np.argsort(scores[0])[::-1][:num_recommendations]\n",
        "        predicted_ratings = []\n",
        "        for movie_id in movie_ids:\n",
        "            if movie_id in actual_ratings['movieId'].values:\n",
        "                predicted_ratings.append(actual_ratings[actual_ratings['movieId'] == movie_id]['rating'].values[0])\n",
        "            else:\n",
        "                predicted_ratings.append(0)  # Assume rating of 0 for movies not in test set\n",
        "        mse_list.append(mean_squared_error([0]*len(predicted_ratings), predicted_ratings))\n",
        "    return np.mean(mse_list)\n",
        "\n",
        "def evaluate_collab_model(recommendation_func, num_recommendations=5, num_neighbors=10):\n",
        "    mse_list = []\n",
        "    for user_id in test_data['userId'].unique():\n",
        "        actual_ratings = test_data[test_data['userId'] == user_id]\n",
        "        if recommendation_func.__name__ == 'hybrid_recommendations':\n",
        "            recommended_movies = recommendation_func(user_id, num_recommendations)\n",
        "        else:\n",
        "            recommended_movies = recommendation_func(user_id, num_recommendations, num_neighbors)\n",
        "        predicted_ratings = []\n",
        "        for movie_id in recommended_movies:\n",
        "            if movie_id in actual_ratings['movieId'].values:\n",
        "                predicted_ratings.append(actual_ratings[actual_ratings['movieId'] == movie_id]['rating'].values[0])\n",
        "            else:\n",
        "                predicted_ratings.append(0)  # Assume rating of 0 for movies not in test set\n",
        "        mse_list.append(mean_squared_error([0]*len(predicted_ratings), predicted_ratings))\n",
        "    return np.mean(mse_list)\n"
      ],
      "metadata": {
        "id": "ihs8t2Kf1Pjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_svd_components():\n",
        "    components = [20, 50, 100]\n",
        "    best_mse = float('inf')\n",
        "    best_components = 0\n",
        "\n",
        "    for n in components:\n",
        "        svd = TruncatedSVD(n_components=n, random_state=42)\n",
        "        svd.fit(user_item_matrix)\n",
        "        mse = evaluate_svd_model(svd, num_recommendations=5)\n",
        "        print(f\"SVD with {n} components: MSE={mse}\")\n",
        "\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_components = n\n",
        "\n",
        "    print(f\"Best SVD MSE: {best_mse} with {best_components} components\")\n",
        "    return best_components\n",
        "\n",
        "best_svd_components = tune_svd_components()\n"
      ],
      "metadata": {
        "id": "AQda7xTO1WjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune the number of neighbors\n",
        "def tune_hyperparameters():\n",
        "    neighbors = [5, 10]\n",
        "    best_user_based_mse = float('inf')\n",
        "    best_item_based_mse = float('inf')\n",
        "    best_user_neighbors = 0\n",
        "    best_item_neighbors = 0\n",
        "\n",
        "    for n in neighbors:\n",
        "        user_based_mse = evaluate_collab_model(user_based_recommendations, num_neighbors=n)\n",
        "        item_based_mse = evaluate_collab_model(item_based_recommendations, num_neighbors=n)\n",
        "        print(f\"User-based CF MSE with {n} neighbors:\", user_based_mse)\n",
        "        print(f\"Item-based CF MSE with {n} neighbors:\", item_based_mse)\n",
        "\n",
        "        if user_based_mse < best_user_based_mse:\n",
        "            best_user_based_mse = user_based_mse\n",
        "            best_user_neighbors = n\n",
        "\n",
        "        if item_based_mse < best_item_based_mse:\n",
        "            best_item_based_mse = item_based_mse\n",
        "            best_item_neighbors = n\n",
        "\n",
        "    print(f\"Best User-based CF MSE: {best_user_based_mse} with {best_user_neighbors} neighbors\")\n",
        "    print(f\"Best Item-based CF MSE: {best_item_based_mse} with {best_item_neighbors} neighbors\")\n",
        "\n",
        "    return best_user_neighbors, best_item_neighbors\n",
        "\n",
        "best_user_neighbors, best_item_neighbors = tune_hyperparameters()\n"
      ],
      "metadata": {
        "id": "FM0jsUVN1XlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid Recommendation System\n",
        "def hybrid_recommendations(user_id, num_recommendations):\n",
        "    svd_recommendations = recommend_movies(user_id, num_recommendations * 3)\n",
        "    user_based_recommendations_list = user_based_recommendations(user_id, num_recommendations * 3, best_user_neighbors)\n",
        "    item_based_recommendations_list = item_based_recommendations(user_id, num_recommendations * 3, best_item_neighbors)\n",
        "\n",
        "    combined_recommendations = list(set(svd_recommendations) | set(user_based_recommendations_list) | set(item_based_recommendations_list))\n",
        "    combined_scores = pd.Series(index=combined_recommendations, dtype=float)\n",
        "\n",
        "    for movie_id in combined_recommendations:\n",
        "        svd_score = 1 if movie_id in svd_recommendations else 0\n",
        "        user_score = 1 if movie_id in user_based_recommendations_list else 0\n",
        "        item_score = 1 if movie_id in item_based_recommendations_list else 0\n",
        "        combined_scores[movie_id] = svd_score + user_score + item_score\n",
        "\n",
        "    return combined_scores.sort_values(ascending=False).index[:num_recommendations]\n",
        "\n",
        "# Example: Recommend 5 movies for user with ID 1 using hybrid filtering\n",
        "hybrid_recommended_movies = hybrid_recommendations(1, 5)\n",
        "print(\"Hybrid Recommended Movies:\", hybrid_recommended_movies)\n",
        "\n",
        "# Evaluate the hybrid model\n",
        "hybrid_mse = evaluate_collab_model(hybrid_recommendations, num_recommendations=5)\n",
        "print(\"Hybrid Collaborative Filtering MSE:\", hybrid_mse)\n"
      ],
      "metadata": {
        "id": "NjDZPSKd1ezP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_precision_recall(recommendation_func, num_recommendations=5):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "\n",
        "    for user_id in test_data['userId'].unique():\n",
        "        actual_ratings = test_data[test_data['userId'] == user_id]\n",
        "        if len(actual_ratings) == 0:\n",
        "            continue\n",
        "        recommended_movies = recommendation_func(user_id, num_recommendations)\n",
        "        relevant_items = actual_ratings[actual_ratings['rating'] >= 4]['movieId']\n",
        "\n",
        "        if len(relevant_items) == 0:\n",
        "            continue\n",
        "\n",
        "        recommended_set = set(recommended_movies)\n",
        "        relevant_set = set(relevant_items)\n",
        "\n",
        "        true_positives = len(recommended_set & relevant_set)\n",
        "        false_positives = len(recommended_set - relevant_set)\n",
        "        false_negatives = len(relevant_set - recommended_set)\n",
        "\n",
        "        if true_positives + false_positives > 0:\n",
        "            precision = true_positives / (true_positives + false_positives)\n",
        "        else:\n",
        "            precision = 0\n",
        "\n",
        "        if true_positives + false_negatives > 0:\n",
        "            recall = true_positives / (true_positives + false_negatives)\n",
        "        else:\n",
        "            recall = 0\n",
        "\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    avg_precision = np.mean(precision_list)\n",
        "    avg_recall = np.mean(recall_list)\n",
        "    f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
        "\n",
        "    return avg_precision, avg_recall, f1\n",
        "\n",
        "# Evaluate precision, recall, and F1-score for the hybrid model\n",
        "precision, recall, f1 = evaluate_precision_recall(hybrid_recommendations, num_recommendations=5)\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "37abJevH1h7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def cross_validate_model(recommendation_func, k=5, num_recommendations=5):\n",
        "    kf = KFold(n_splits=k)\n",
        "    mse_list = []\n",
        "\n",
        "    for train_index, test_index in kf.split(ratings):\n",
        "        train_data = ratings.iloc[train_index]\n",
        "        test_data = ratings.iloc[test_index]\n",
        "\n",
        "        user_item_matrix = train_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "        svd = TruncatedSVD(n_components=best_svd_components, random_state=42)\n",
        "        matrix_svd = svd.fit_transform(user_item_matrix)\n",
        "\n",
        "        mse = evaluate_collab_model(recommendation_func, num_recommendations=num_recommendations)\n",
        "        mse_list.append(mse)\n",
        "\n",
        "    avg_mse = np.mean(mse_list)\n",
        "    print(f\"Cross-Validated MSE: {avg_mse}\")\n",
        "    return avg_mse\n",
        "\n",
        "# Cross-validate the hybrid model\n",
        "cross_validate_model(hybrid_recommendations, k=5, num_recommendations=5)\n"
      ],
      "metadata": {
        "id": "iXhizGBY11zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **These are the visualisations if interested**"
      ],
      "metadata": {
        "id": "cxhHtDv715u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot heatmap of user similarities\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(user_similarity_df, cmap='coolwarm', xticklabels=False, yticklabels=False)\n",
        "plt.title(\"User Similarities\")\n",
        "plt.show()\n",
        "\n",
        "# Plot heatmap of item similarities\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(item_similarity_df, cmap='coolwarm', xticklabels=False, yticklabels=False)\n",
        "plt.title(\"Item Similarities\")\n",
        "plt.show()\n",
        "\n",
        "# Plot distribution of ratings\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(ratings['rating'], bins=20, kde=True)\n",
        "plt.title(\"Rating Distribution\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L2QuMmVM141Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/recommend', methods=['GET'])\n",
        "def recommend():\n",
        "    user_id = int(request.args.get('user_id'))\n",
        "    num_recommendations = int(request.args.get('num_recommendations', 5))\n",
        "    recommendations = hybrid_recommendations(user_id, num_recommendations)\n",
        "    return jsonify(recommendations.tolist())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "T_d3jzvE2PEP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}